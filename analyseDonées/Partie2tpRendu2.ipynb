{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWoa8mCwtqky"
      },
      "outputs": [],
      "source": [
        "#Ce travail était fait par OUCOUC Hafid,Maouche Massinissa et Dinel Debib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "\n",
        "# Ignorer les avertissements de convergence\n",
        "warnings.filterwarnings('ignore', category=ConvergenceWarning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgO3J_sC1s3I"
      },
      "source": [
        "# ***Chargement des données et préparation***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3jDnsLwC8zY",
        "outputId": "538b857f-37f7-44c1-ace9-6d4a45a71432"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_numeric après traitement des valeurs manquantes:\n",
            "      1      2     7   10     13   14\n",
            "0  30.83  0.000  1.25   1  202.0    0\n",
            "1  58.67  4.460  3.04   6   43.0  560\n",
            "2  24.50  0.500  1.50   0  280.0  824\n",
            "3  27.83  1.540  3.75   5  100.0    3\n",
            "4  20.17  5.625  1.71   0  120.0    0\n",
            "Taille de l'échantillon: (666, 6)\n",
            "Nombre d'exemples positifs: 299\n",
            "Nombre d'exemples négatifs: 367\n",
            "RandomForest: AUC = 0.84 (+/- 0.05)\n",
            "LogisticRegression: AUC = 0.83 (+/- 0.06)\n",
            "KNN: AUC = 0.70 (+/- 0.02)\n",
            "SVM: AUC = 0.70 (+/- 0.04)\n"
          ]
        }
      ],
      "source": [
        "# Chargement des données\n",
        "data = pd.read_csv('/content/credit.data', sep='\\t', header=None)\n",
        "\n",
        "# Séparation des caractéristiques et de la cible\n",
        "X = data.iloc[:, :-1]  # Caractéristiques\n",
        "y = data.iloc[:, -1]   # Cible\n",
        "\n",
        "# Identification des colonnes numériques\n",
        "numeric_columns = [1, 2, 7, 10, 13, 14]  # Colonnes qui devraient être numériques\n",
        "\n",
        "# Remplacer '?' par NaN et convertir en float\n",
        "for col in numeric_columns:\n",
        "    X[col] = pd.to_numeric(X[col], errors='coerce')\n",
        "\n",
        "# Suppression des lignes avec des valeurs NaN\n",
        "X_numeric = X[numeric_columns].dropna()\n",
        "\n",
        "# Mise à jour de la cible en fonction des lignes supprimées\n",
        "y = y[X_numeric.index]\n",
        "\n",
        "# Vérification des données\n",
        "print(\"X_numeric après traitement des valeurs manquantes:\")\n",
        "print(X_numeric.head())\n",
        "print(\"Taille de l'échantillon:\", X_numeric.shape)\n",
        "print(\"Nombre d'exemples positifs:\", (y == '+').sum())\n",
        "print(\"Nombre d'exemples négatifs:\", (y == '-').sum())\n",
        "\n",
        "# Binarisation de la cible\n",
        "lb = LabelBinarizer()\n",
        "y_binary = lb.fit_transform(y).ravel()  # Convertit '+' en 1 et '-' en 0\n",
        "\n",
        "# Fonction pour exécuter les classificateurs\n",
        "def run_classifiers(clfs, X, y):\n",
        "    for clf_name, clf in clfs.items():\n",
        "        scores = cross_val_score(clf, X, y, cv=5, scoring='roc_auc')\n",
        "        print(f\"{clf_name}: AUC = {np.mean(scores):.2f} (+/- {np.std(scores):.2f})\")\n",
        "\n",
        "# Autres classificateurs pour la comparaison\n",
        "rf_classifier = RandomForestClassifier()\n",
        "logistic_regression = LogisticRegression(max_iter=1000)  # Augmentation du nombre d'itérations\n",
        "knn_classifier = KNeighborsClassifier()\n",
        "svm_classifier = SVC(probability=True)  # probability=True pour permettre l'AUC\n",
        "\n",
        "# Ajout des classificateurs au dictionnaire\n",
        "classifiers = {\n",
        "    'RandomForest': rf_classifier,\n",
        "    'LogisticRegression': logistic_regression,\n",
        "    'KNN': knn_classifier,\n",
        "    'SVM': svm_classifier\n",
        "}\n",
        "\n",
        "run_classifiers(classifiers, X_numeric, y_binary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsLiWuae166D"
      },
      "source": [
        "# ***Normalisation des variables continues***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pOVO26pB9hy",
        "outputId": "8e776694-f0b2-419f-afb8-5f6c8ca408f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RandomForest: AUC = 0.84 (+/- 0.05)\n",
            "LogisticRegression: AUC = 0.82 (+/- 0.06)\n",
            "KNN: AUC = 0.81 (+/- 0.06)\n",
            "SVM: AUC = 0.83 (+/- 0.06)\n"
          ]
        }
      ],
      "source": [
        "# Normalisation des données avec StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_numeric)\n",
        "\n",
        "# Ou, normalisation des données avec MinMaxScaler\n",
        "# scaler = MinMaxScaler()\n",
        "# X_scaled = scaler.fit_transform(X_numeric)\n",
        "\n",
        "# Exécuter les classificateurs avec les données normalisées\n",
        "run_classifiers(classifiers, X_scaled, y_binary)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igITwE6o2Ebj"
      },
      "source": [
        "# ***Traitement de données manquantes***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9SkpQitsr-s",
        "outputId": "2798a381-b387-4540-bfb6-117b899ccac6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RandomForest: AUC = 0.86 (+/- 0.05)\n",
            "LogisticRegression: AUC = 0.82 (+/- 0.05)\n",
            "KNN: AUC = 0.72 (+/- 0.04)\n",
            "SVM: AUC = 0.69 (+/- 0.05)\n"
          ]
        }
      ],
      "source": [
        "# Chargement des données\n",
        "data = pd.read_csv('/content/credit.data', sep='\\t', header=None)\n",
        "\n",
        "# Séparation des caractéristiques et de la cible\n",
        "X = data.iloc[:, :-1].values  # Caractéristiques\n",
        "y = data.iloc[:, -1].values   # Cible\n",
        "\n",
        "# Identification des colonnes catégorielles et numériques\n",
        "col_cat = [0, 3, 4, 5, 6, 8, 9, 11, 12]  # Indices des colonnes catégorielles\n",
        "col_num = [i for i in range(X.shape[1]) if i not in col_cat]  # Indices des colonnes numériques\n",
        "\n",
        "# Conversion des variables catégorielles en valeurs numériques\n",
        "label_encoders = []\n",
        "X_cat = np.copy(X[:, col_cat])\n",
        "for col_id in range(X_cat.shape[1]):\n",
        "    le = LabelEncoder()\n",
        "    X_cat[:, col_id] = le.fit_transform(X_cat[:, col_id].astype(str))\n",
        "    label_encoders.append(le)\n",
        "\n",
        "# Imputation pour les variables catégorielles\n",
        "imp_cat = SimpleImputer(missing_values=0, strategy='most_frequent')\n",
        "X_cat = imp_cat.fit_transform(X_cat)\n",
        "\n",
        "# Traitement des variables numériques\n",
        "X_num = np.copy(X[:, col_num])\n",
        "X_num[X_num == '?'] = np.nan\n",
        "X_num = X_num.astype(float)\n",
        "\n",
        "# Imputation pour les variables numériques\n",
        "imp_num = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "X_num = imp_num.fit_transform(X_num)\n",
        "\n",
        "# Fusion des variables catégorielles et numériques\n",
        "X_combined = np.hstack((X_cat, X_num))\n",
        "\n",
        "# Binarisation de la cible\n",
        "lb = LabelBinarizer()\n",
        "y_binary = lb.fit_transform(y).ravel()\n",
        "\n",
        "# Définition des classificateurs\n",
        "classifiers = {\n",
        "    'RandomForest': RandomForestClassifier(),\n",
        "    'LogisticRegression': LogisticRegression(max_iter=1000),\n",
        "    'KNN': KNeighborsClassifier(),\n",
        "    'SVM': SVC(probability=True)\n",
        "}\n",
        "\n",
        "# Fonction pour exécuter les classificateurs\n",
        "def run_classifiers(clfs, X, y):\n",
        "    for clf_name, clf in clfs.items():\n",
        "        scores = cross_val_score(clf, X, y, cv=5, scoring='roc_auc')\n",
        "        print(f\"{clf_name}: AUC = {np.mean(scores):.2f} (+/- {np.std(scores):.2f})\")\n",
        "\n",
        "\n",
        "# Exécution des classificateurs sur le jeu de données imputé\n",
        "run_classifiers(classifiers, X_combined, y_binary)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgBBAjRO2KqK"
      },
      "source": [
        "# ***Traitement de variables catégorielles***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzNYlHYIxNM6",
        "outputId": "853684d6-e0d9-47f4-fdbd-2eca3386ea86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RandomForest: AUC = 0.85 (+/- 0.05)\n",
            "LogisticRegression: AUC = 0.83 (+/- 0.06)\n",
            "KNN: AUC = 0.71 (+/- 0.05)\n",
            "SVM: AUC = 0.69 (+/- 0.05)\n"
          ]
        }
      ],
      "source": [
        "# Encodage One-Hot pour les variables catégorielles\n",
        "onehot_encoder = OneHotEncoder()\n",
        "X_cat_bin = onehot_encoder.fit_transform(X_cat).toarray()\n",
        "\n",
        "# Fusion des variables catégorielles encodées et numériques\n",
        "X_combined_bin = np.hstack((X_cat_bin, X_num))\n",
        "\n",
        "# Exécution des classificateurs sur le jeu de données avec encodage one-hot\n",
        "run_classifiers(classifiers, X_combined_bin, y_binary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxtmg7od2TOr"
      },
      "source": [
        "# ***Construction du jeu de données***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AIFFpxfzOOp",
        "outputId": "f9d739fc-ae99-46d0-daf4-eb6ea27bc5e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RandomForest: AUC = 0.84 (+/- 0.05)\n",
            "LogisticRegression: AUC = 0.83 (+/- 0.06)\n",
            "KNN: AUC = 0.76 (+/- 0.05)\n",
            "SVM: AUC = 0.84 (+/- 0.06)\n"
          ]
        }
      ],
      "source": [
        "# Normalisation des variables numériques\n",
        "scaler = StandardScaler()\n",
        "X_num_scaled = scaler.fit_transform(X_num)\n",
        "\n",
        "# Encodage One-Hot pour les variables catégorielles\n",
        "onehot_encoder = OneHotEncoder()\n",
        "X_cat_bin = onehot_encoder.fit_transform(X_cat).toarray()\n",
        "\n",
        "# Construction du jeu de données final\n",
        "X_final = np.hstack((X_cat_bin, X_num_scaled))\n",
        "\n",
        "# Définition et exécution des classificateurs sur le jeu de données final\n",
        "run_classifiers(classifiers, X_final, y_binary)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
